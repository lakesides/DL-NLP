
<!DOCTYPE HTML>
<html lang="" >
    <head>
        <meta charset="UTF-8">
        <meta content="text/html; charset=utf-8" http-equiv="Content-Type">
        <title>seq2seq模型的原理 · GitBook</title>
        <meta http-equiv="X-UA-Compatible" content="IE=edge" />
        <meta name="description" content="">
        <meta name="generator" content="GitBook 3.2.3">
        
        
        
    
    <link rel="stylesheet" href="../gitbook/style.css">

    
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-highlight/website.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-search/search.css">
                
            
                
                <link rel="stylesheet" href="../gitbook/gitbook-plugin-fontsettings/website.css">
                
            
        

    

    
        
    
        
    
        
    
        
    
        
    
        
    

        
    
    
    <meta name="HandheldFriendly" content="true"/>
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="apple-mobile-web-app-capable" content="yes">
    <meta name="apple-mobile-web-app-status-bar-style" content="black">
    <link rel="apple-touch-icon-precomposed" sizes="152x152" href="../gitbook/images/apple-touch-icon-precomposed-152.png">
    <link rel="shortcut icon" href="../gitbook/images/favicon.ico" type="image/x-icon">

    
    <link rel="next" href="2.3.3 seq2seq实现闲聊机器人.html" />
    
    
    <link rel="prev" href="2.3.1 闲聊机器人的介绍.html" />
    

    </head>
    <body>
        
<div class="book">
    <div class="book-summary">
        
            
<div id="book-search-input" role="search">
    <input type="text" placeholder="Type to search" />
</div>

            
                <nav role="navigation">
                


<ul class="summary">
    
    

    

    
        
        
    
        <li class="chapter " data-level="1.1" data-path="../">
            
                <a href="../">
            
                    
                    Introduction
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2" >
            
                <span>
            
                    
                    神经网络和pytorch
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1" data-path="../1.1 深度学习和神经网络/">
            
                <a href="../1.1 深度学习和神经网络/">
            
                    
                    1.1 深度学习和神经网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.1.1" data-path="../1.1 深度学习和神经网络/1.1.1 深度学习的介绍.html">
            
                <a href="../1.1 深度学习和神经网络/1.1.1 深度学习的介绍.html">
            
                    
                    深度学习的介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.1.2" data-path="../1.1 深度学习和神经网络/1.1.2 神经网络的介绍.html">
            
                <a href="../1.1 深度学习和神经网络/1.1.2 神经网络的介绍.html">
            
                    
                    神经网络的介绍
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.2" data-path="../1.2 pytorch/">
            
                <a href="../1.2 pytorch/">
            
                    
                    1.2 pytorch
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.2.1" data-path="../1.2 pytorch/1.2.1 pytorch的介绍和安装.html">
            
                <a href="../1.2 pytorch/1.2.1 pytorch的介绍和安装.html">
            
                    
                    pytorch的介绍和安装
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.2" data-path="../1.2 pytorch/1.2.2 pytorch的入门使用.html">
            
                <a href="../1.2 pytorch/1.2.2 pytorch的入门使用.html">
            
                    
                    pytorch的入门使用
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.3" data-path="../1.2 pytorch/1.2.3 梯度下降和反向传播原理.html">
            
                <a href="../1.2 pytorch/1.2.3 梯度下降和反向传播原理.html">
            
                    
                    梯度下降和反向传播原理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.4" data-path="../1.2 pytorch/1.2.4 手动完成线性回归 .html">
            
                <a href="../1.2 pytorch/1.2.4 手动完成线性回归 .html">
            
                    
                    手动完成线性回归 
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.5" data-path="../1.2 pytorch/1.2.5调用 pytorch API完成线性回归.html">
            
                <a href="../1.2 pytorch/1.2.5调用 pytorch API完成线性回归.html">
            
                    
                    调用 pytorch API完成线性回归
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.6" data-path="../1.2 pytorch/1.2.6 pytorch中的数据加载.html">
            
                <a href="../1.2 pytorch/1.2.6 pytorch中的数据加载.html">
            
                    
                    pytorch中的数据加载
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.2.7" data-path="../1.2 pytorch/1.2.7 使用pytorch实现手写数字识别.html">
            
                <a href="../1.2 pytorch/1.2.7 使用pytorch实现手写数字识别.html">
            
                    
                    使用pytorch实现手写数字识别
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.2.3" data-path="../1.3 循环神经网络/">
            
                <a href="../1.3 循环神经网络/">
            
                    
                    1.3 循环神经网络
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.2.3.1" data-path="../1.3 循环神经网络/1.3.1 循环神经网络基础.html">
            
                <a href="../1.3 循环神经网络/1.3.1 循环神经网络基础.html">
            
                    
                    循环神经网络基础
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.2" data-path="../1.3 循环神经网络/1.3.2 文本情感分类.html">
            
                <a href="../1.3 循环神经网络/1.3.2 文本情感分类.html">
            
                    
                    文本情感分类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.3" data-path="../1.3 循环神经网络/1.3.3 循环神经网络.html">
            
                <a href="../1.3 循环神经网络/1.3.3 循环神经网络.html">
            
                    
                    循环神经网络
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.4" data-path="../1.3 循环神经网络/1.3.4 循环神经网络实现情感分类.html">
            
                <a href="../1.3 循环神经网络/1.3.4 循环神经网络实现情感分类.html">
            
                    
                    循环神经网络实现情感分类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.5" data-path="../1.3 循环神经网络/1.3.5 神经网络中的序列化容器.html">
            
                <a href="../1.3 循环神经网络/1.3.5 神经网络中的序列化容器.html">
            
                    
                    神经网络中的序列化容器
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.2.3.6" data-path="../1.3 循环神经网络/1.3.6 神经网络实现分词.html">
            
                <a href="../1.3 循环神经网络/1.3.6 神经网络实现分词.html">
            
                    
                    神经网络实现分词
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3" >
            
                <span>
            
                    
                    项目实现
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1" data-path="../2.1 项目准备/">
            
                <a href="../2.1 项目准备/">
            
                    
                    2.1 项目装备
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.1.1" data-path="../2.1 项目准备/2.1.1 走进聊天机器人.html">
            
                <a href="../2.1 项目准备/2.1.1 走进聊天机器人.html">
            
                    
                    走进聊天机器人
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.2" data-path="../2.1 项目准备/2.1.2 需求分析和流程介绍.html">
            
                <a href="../2.1 项目准备/2.1.2 需求分析和流程介绍.html">
            
                    
                    需求分析和流程介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.3" data-path="../2.1 项目准备/2.1.3 环境准备.html">
            
                <a href="../2.1 项目准备/2.1.3 环境准备.html">
            
                    
                    环境准备
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.4" data-path="../2.1 项目准备/2.1.4 语料准备.html">
            
                <a href="../2.1 项目准备/2.1.4 语料准备.html">
            
                    
                    语料准备
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.5" data-path="../2.1 项目准备/2.1.5 文本分词.html">
            
                <a href="../2.1 项目准备/2.1.5 文本分词.html">
            
                    
                    文本分词
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.1.6" data-path="../2.1 项目准备/2.1.6 动手练习.html">
            
                <a href="../2.1 项目准备/2.1.6 动手练习.html">
            
                    
                    动手练习
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.2" data-path="../2.2 fasttext文本分类/">
            
                <a href="../2.2 fasttext文本分类/">
            
                    
                    2.2 FastText文本分类
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.2.1" data-path="../2.2 fasttext文本分类/2.2.1 分类的目的和方法.html">
            
                <a href="../2.2 fasttext文本分类/2.2.1 分类的目的和方法.html">
            
                    
                    分类的目的和方法
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.2" data-path="../2.2 fasttext文本分类/2.2.2 fasttext实现文本分类.html">
            
                <a href="../2.2 fasttext文本分类/2.2.2 fasttext实现文本分类.html">
            
                    
                    fasttext实现文本分类
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.2.3" data-path="../2.2 fasttext文本分类/2.2.3 fasttext的原理剖析.html">
            
                <a href="../2.2 fasttext文本分类/2.2.3 fasttext的原理剖析.html">
            
                    
                    fasttext的原理剖析
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.3" data-path="./">
            
                <a href="./">
            
                    
                    2.3 Seq2Seq模型和闲聊机器人
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.3.1" data-path="2.3.1 闲聊机器人的介绍.html">
            
                <a href="2.3.1 闲聊机器人的介绍.html">
            
                    
                    闲聊机器人的介绍
            
                </a>
            

            
        </li>
    
        <li class="chapter active" data-level="1.3.3.2" data-path="2.3.2 seq2seq模型的原理.html">
            
                <a href="2.3.2 seq2seq模型的原理.html">
            
                    
                    seq2seq模型的原理
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.3" data-path="2.3.3 seq2seq实现闲聊机器人.html">
            
                <a href="2.3.3 seq2seq实现闲聊机器人.html">
            
                    
                    seq2seq实现闲聊机器人
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.4" data-path="2.3.4 Attention的原理和实现.html">
            
                <a href="2.3.4 Attention的原理和实现.html">
            
                    
                    Attention的原理和实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.5" data-path="2.3.5 BeamSearch的原理和实现.html">
            
                <a href="2.3.5 BeamSearch的原理和实现.html">
            
                    
                    BeamSearch的原理和实现
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.3.6" data-path="2.3.6 闲聊机器人的优化.html">
            
                <a href="2.3.6 闲聊机器人的优化.html">
            
                    
                    闲聊机器人的优化
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.3.4" data-path="../2.4 QA机器人/">
            
                <a href="../2.4 QA机器人/">
            
                    
                    2.4 QA机器人
            
                </a>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.3.4.1" data-path="../2.4 QA机器人/2.4.1 QA机器人介绍.html">
            
                <a href="../2.4 QA机器人/2.4.1 QA机器人介绍.html">
            
                    
                    QA机器人介绍.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.2" data-path="../2.4 QA机器人/2.4.2 QA机器人的召回.html">
            
                <a href="../2.4 QA机器人/2.4.2 QA机器人的召回.html">
            
                    
                    QA机器人的召回.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.3" data-path="../2.4 QA机器人/2.4.3 召回优化.html">
            
                <a href="../2.4 QA机器人/2.4.3 召回优化.html">
            
                    
                    召回优化.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.4" data-path="../2.4 QA机器人/2.4.4 QA机器人排序模型.html">
            
                <a href="../2.4 QA机器人/2.4.4 QA机器人排序模型.html">
            
                    
                    QA机器人排序模型.md
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.3.4.5" data-path="../2.4 QA机器人/2.4.5 代码的封装和提供接口.html">
            
                <a href="../2.4 QA机器人/2.4.5 代码的封装和提供接口.html">
            
                    
                    代码的封装和提供接口.md
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

            </ul>
            
        </li>
    
        <li class="chapter " data-level="1.4" >
            
                <span>
            
                    
                    补充
            
                </span>
            

            
            <ul class="articles">
                
    
        <li class="chapter " data-level="1.4.1" data-path="../补充/HMM.html">
            
                <a href="../补充/HMM.html">
            
                    
                    HMM
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.2" data-path="../补充/MEMM和CRF.html">
            
                <a href="../补充/MEMM和CRF.html">
            
                    
                    MEMM和CRF
            
                </a>
            

            
        </li>
    
        <li class="chapter " data-level="1.4.3" data-path="../补充/最大匹配法.html">
            
                <a href="../补充/最大匹配法.html">
            
                    
                    最大匹配法
            
                </a>
            

            
        </li>
    

            </ul>
            
        </li>
    

    

    <li class="divider"></li>

    <li>
        <a href="https://www.gitbook.com" target="blank" class="gitbook-link">
            Published with GitBook
        </a>
    </li>
</ul>


                </nav>
            
        
    </div>

    <div class="book-body">
        
            <div class="body-inner">
                
                    

<div class="book-header" role="navigation">
    

    <!-- Title -->
    <h1>
        <i class="fa fa-circle-o-notch fa-spin"></i>
        <a href=".." >seq2seq模型的原理</a>
    </h1>
</div>




                    <div class="page-wrapper" tabindex="-1" role="main">
                        <div class="page-inner">
                            
<div id="book-search-results">
    <div class="search-noresults">
    
                                <section class="normal markdown-section">
                                
                                <h1 id="seq2seq&#x6A21;&#x578B;&#x7684;&#x539F;&#x7406;">Seq2Seq&#x6A21;&#x578B;&#x7684;&#x539F;&#x7406;</h1>
<h2 id="&#x76EE;&#x6807;">&#x76EE;&#x6807;</h2>
<ol>
<li>&#x77E5;&#x9053;seq2seq&#x7684;&#x5E38;&#x89C1;&#x5E94;&#x7528;&#x573A;&#x666F;</li>
<li>&#x80FD;&#x591F;&#x8BF4;&#x51FA;&#x5E38;&#x89C1;&#x7684;seq2seq&#x7684;&#x7ED3;&#x6784;</li>
<li>&#x80FD;&#x591F;&#x4F7F;&#x7528;&#x4EE3;&#x7801;&#x5B8C;&#x6210;&#x57FA;&#x7840;&#x7684;seq2seq&#x7684;&#x7ED3;&#x6784;</li>
</ol>
<h2 id="1-seq2seq&#x7684;&#x4ECB;&#x7ECD;">1. Seq2Seq&#x7684;&#x4ECB;&#x7ECD;</h2>
<p><img src="../images/2.3/seq2seq.png" alt=""></p>
<p><code>Sequence to sequence (seq2seq)</code>&#x662F;&#x7531;<code>encoder&#xFF08;&#x7F16;&#x7801;&#x5668;&#xFF09;</code>&#x548C;<code>decoder&#xFF08;&#x89E3;&#x7801;&#x5668;&#xFF09;</code>&#x4E24;&#x4E2A;RNN&#x7684;&#x7EC4;&#x6210;&#x7684;&#x3002;&#x5176;&#x4E2D;encoder&#x8D1F;&#x8D23;&#x5BF9;&#x8F93;&#x5165;&#x53E5;&#x5B50;&#x7684;&#x7406;&#x89E3;&#xFF0C;&#x8F6C;&#x5316;&#x4E3A;<code>context vector</code>&#xFF0C;decoder&#x8D1F;&#x8D23;&#x5BF9;&#x7406;&#x89E3;&#x540E;&#x7684;&#x53E5;&#x5B50;&#x7684;&#x5411;&#x91CF;&#x8FDB;&#x884C;&#x5904;&#x7406;&#xFF0C;&#x89E3;&#x7801;&#xFF0C;&#x83B7;&#x5F97;&#x8F93;&#x51FA;&#x3002;&#x4E0A;&#x8FF0;&#x7684;&#x8FC7;&#x7A0B;&#x548C;&#x6211;&#x4EEC;&#x5927;&#x8111;&#x7406;&#x89E3;&#x4E1C;&#x897F;&#x7684;&#x8FC7;&#x7A0B;&#x5F88;&#x76F8;&#x4F3C;&#xFF0C;<code>&#x542C;&#x5230;&#x4E00;&#x53E5;&#x8BDD;&#xFF0C;&#x7406;&#x89E3;&#x4E4B;&#x540E;&#xFF0C;&#x5C1D;&#x8BD5;&#x7EC4;&#x88C5;&#x7B54;&#x6848;&#xFF0C;&#x8FDB;&#x884C;&#x56DE;&#x7B54;</code></p>
<p>&#x90A3;&#x4E48;&#x6B64;&#x65F6;&#xFF0C;&#x5C31;&#x6709;&#x4E00;&#x4E2A;&#x95EE;&#x9898;&#xFF0C;&#x5728;encoder&#x7684;&#x8FC7;&#x7A0B;&#x4E2D;&#x5F97;&#x5230;&#x7684;context vector&#x4F5C;&#x4E3A;decoder&#x7684;&#x8F93;&#x5165;&#xFF0C;&#x90A3;&#x4E48;&#x8FD9;&#x6837;&#x4E00;&#x4E2A;&#x8F93;&#x5165;&#xFF0C;&#x600E;&#x4E48;&#x80FD;&#x591F;&#x5F97;&#x5230;&#x591A;&#x4E2A;&#x8F93;&#x51FA;&#x5462;&#xFF1F;</p>
<p>&#x5176;&#x5B9E;&#x5C31;&#x662F;<code>&#x5F53;&#x524D;&#x4E00;&#x6B65;&#x7684;&#x8F93;&#x51FA;&#xFF0C;&#x4F5C;&#x4E3A;&#x4E0B;&#x4E00;&#x4E2A;&#x5355;&#x5143;&#x7684;&#x8F93;&#x5165;&#xFF0C;&#x7136;&#x540E;&#x5F97;&#x5230;&#x7ED3;&#x679C;</code></p>
<pre><code class="lang-python">outputs = []
<span class="hljs-keyword">while</span> <span class="hljs-keyword">True</span>:
    output = decoderd(output)
    outputs.append(output)
</code></pre>
<p>&#x90A3;&#x4E48;&#x5FAA;&#x73AF;&#x4EC0;&#x4E48;&#x65F6;&#x5019;&#x505C;&#x6B62;&#x5462;&#xFF1F;</p>
<p>&#x5728;&#x8BAD;&#x7EC3;&#x6570;&#x636E;&#x96C6;&#x4E2D;&#xFF0C;&#x53EF;&#x4EE5;&#x518D;&#x8F93;&#x51FA;&#x7684;&#x6700;&#x540E;&#x9762;&#x6DFB;&#x52A0;&#x4E00;&#x4E2A;&#x7ED3;&#x675F;&#x7B26;<code>&lt;END&gt;</code>&#xFF0C;&#x5982;&#x679C;&#x9047;&#x5230;&#x8BE5;&#x7ED3;&#x675F;&#x7B26;&#xFF0C;&#x5219;&#x53EF;&#x4EE5;&#x7EC8;&#x6B62;&#x5FAA;&#x73AF;</p>
<pre><code class="lang-python">outputs = []
<span class="hljs-keyword">while</span> output!=<span class="hljs-string">&quot;&lt;END&gt;&quot;</span>:
    output = decoderd(output)
    outputs.append(output)
</code></pre>
<p>&#x8FD9;&#x4E2A;&#x7ED3;&#x675F;&#x7B26;&#x53EA;&#x662F;&#x4E00;&#x4E2A;&#x6807;&#x8BB0;&#xFF0C;&#x5F88;&#x591A;&#x4EBA;&#x4E5F;&#x4F1A;&#x4F7F;&#x7528;<code>&lt;EOS&gt;(End Of Sentence)</code></p>
<p>&#x603B;&#x4E4B;&#xFF1A;Seq2seq&#x6A21;&#x578B;&#x4E2D;&#x7684;encoder&#x63A5;&#x53D7;&#x4E00;&#x4E2A;&#x957F;&#x5EA6;&#x4E3A;M&#x7684;&#x5E8F;&#x5217;&#xFF0C;&#x5F97;&#x5230;1&#x4E2A; context vector&#xFF0C;&#x4E4B;&#x540E;decoder&#x628A;&#x8FD9;&#x4E00;&#x4E2A;context vector&#x8F6C;&#x5316;&#x4E3A;&#x957F;&#x5EA6;&#x4E3A;N&#x7684;&#x5E8F;&#x5217;&#x4F5C;&#x4E3A;&#x8F93;&#x51FA;&#xFF0C;&#x4ECE;&#x800C;&#x6784;&#x6210;&#x4E00;&#x4E2A;<code>M to N</code>&#x7684;&#x6A21;&#x578B;&#xFF0C;&#x80FD;&#x591F;&#x5904;&#x7406;&#x5F88;&#x591A;&#x4E0D;&#x5B9A;&#x957F;&#x8F93;&#x5165;&#x8F93;&#x51FA;&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x6BD4;&#x5982;&#xFF1A;<code>&#x6587;&#x672C;&#x7FFB;&#x8BD1;&#xFF0C;&#x95EE;&#x7B54;&#xFF0C;&#x6587;&#x7AE0;&#x6458;&#x8981;&#xFF0C;&#x5173;&#x952E;&#x5B57;&#x5199;&#x8BD7;&#x7B49;&#x7B49;</code></p>
<h2 id="2-seq2seq&#x6A21;&#x578B;&#x7684;&#x5B9E;&#x73B0;">2. Seq2Seq&#x6A21;&#x578B;&#x7684;&#x5B9E;&#x73B0;</h2>
<p>&#x4E0B;&#x9762;&#xFF0C;&#x6211;&#x4EEC;&#x901A;&#x8FC7;&#x4E00;&#x4E2A;&#x7B80;&#x5355;&#x7684;&#x5217;&#x5B50;&#xFF0C;&#x6765;&#x770B;&#x770B;&#x666E;&#x901A;&#x7684;Seq2Seq&#x6A21;&#x578B;&#x5E94;&#x8BE5;&#x5982;&#x4F55;&#x5B9E;&#x73B0;&#x3002;</p>
<p><strong>&#x9700;&#x6C42;</strong>&#xFF1A;&#x5B8C;&#x6210;&#x4E00;&#x4E2A;&#x6A21;&#x578B;&#xFF0C;&#x5B9E;&#x73B0;&#x5F80;&#x6A21;&#x578B;&#x8F93;&#x5165;&#x4E00;&#x4E32;&#x6570;&#x5B57;&#xFF0C;&#x8F93;&#x51FA;&#x8FD9;&#x4E32;&#x6570;&#x5B57;+0</p>
<p><strong>&#x4F8B;&#x5982;</strong>&#xFF1A;</p>
<ul>
<li>&#x8F93;&#x5165;<code>123456789</code>&#xFF0C;&#x8F93;&#x51FA;<code>1234567890</code>&#xFF1B;</li>
<li>&#x8F93;&#x5165;<code>52555568</code>&#xFF0C;&#x8F93;&#x51FA;<code>525555680</code></li>
</ul>
<h3 id="21-&#x5B9E;&#x73B0;&#x6D41;&#x7A0B;">2.1 &#x5B9E;&#x73B0;&#x6D41;&#x7A0B;</h3>
<ol>
<li>&#x6587;&#x672C;&#x8F6C;&#x5316;&#x4E3A;&#x5E8F;&#x5217;&#xFF08;&#x6570;&#x5B57;&#x5E8F;&#x5217;&#xFF0C;<code>torch.LongTensor</code>&#xFF09;</li>
<li>&#x4F7F;&#x7528;&#x5E8F;&#x5217;&#xFF0C;&#x51C6;&#x5907;&#x6570;&#x636E;&#x96C6;&#xFF0C;&#x51C6;&#x5907;<code>Dataloader</code></li>
<li>&#x5B8C;&#x6210;&#x7F16;&#x7801;&#x5668;</li>
<li>&#x5B8C;&#x6210;&#x89E3;&#x7801;&#x5668;</li>
<li>&#x5B8C;&#x6210;seq2seq&#x6A21;&#x578B;</li>
<li>&#x5B8C;&#x6210;&#x6A21;&#x578B;&#x8BAD;&#x7EC3;&#x7684;&#x903B;&#x8F91;&#xFF0C;&#x8FDB;&#x884C;&#x8BAD;&#x7EC3;</li>
<li>&#x5B8C;&#x6210;&#x6A21;&#x578B;&#x8BC4;&#x4F30;&#x7684;&#x903B;&#x8F91;&#xFF0C;&#x8FDB;&#x884C;&#x6A21;&#x578B;&#x8BC4;&#x4F30;</li>
</ol>
<h3 id="22-&#x6587;&#x672C;&#x8F6C;&#x5316;&#x4E3A;&#x5E8F;&#x5217;">2.2 &#x6587;&#x672C;&#x8F6C;&#x5316;&#x4E3A;&#x5E8F;&#x5217;</h3>
<p>&#x7531;&#x4E8E;&#x8F93;&#x5165;&#x7684;&#x662F;&#x6570;&#x5B57;&#xFF0C;&#x4E3A;&#x4E86;&#x628A;&#x8FD9;&#x5199;&#x6570;&#x5B57;&#x548C;&#x8BCD;&#x5178;&#x4E2D;&#x7684;&#x771F;&#x5B9E;&#x6570;&#x5B57;&#x8FDB;&#x884C;&#x5BF9;&#x5E94;&#xFF0C;&#x53EF;&#x4EE5;&#x628A;&#x8FD9;&#x4E9B;&#x6570;&#x5B57;&#x7406;&#x89E3;&#x4E3A;&#x5B57;&#x7B26;&#x4E32;</p>
<p>&#x90A3;&#x4E48;&#x6211;&#x4EEC;&#x9700;&#x8981;&#x505A;&#x7684;&#x5C31;&#x662F;&#xFF1A;</p>
<ol>
<li>&#x628A;&#x5B57;&#x7B26;&#x4E32;&#x5BF9;&#x5E94;&#x4E3A;&#x6570;&#x5B57;</li>
<li>&#x628A;&#x6570;&#x5B57;&#x8F6C;&#x5316;&#x4E3A;&#x5B57;&#x7B26;&#x4E32;</li>
</ol>
<p>&#x5B8C;&#x6210;&#x903B;&#x8F91;&#x548C;&#x4E4B;&#x524D;&#x76F8;&#x540C;&#xFF0C;&#x521B;&#x5EFA;<code>word_sequence.py</code>&#x6587;&#x4EF6;&#xFF0C;&#x5B9E;&#x73B0;&#x4E0A;&#x8FF0;&#x903B;&#x8F91;</p>
<pre><code class="lang-python">
<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NumSequence</span>:</span>
    UNK_TAG = <span class="hljs-string">&quot;UNK&quot;</span> <span class="hljs-comment">#&#x672A;&#x77E5;&#x8BCD;</span>
    PAD_TAG = <span class="hljs-string">&quot;PAD&quot;</span> <span class="hljs-comment">#&#x586B;&#x5145;&#x8BCD;&#xFF0C;&#x5B9E;&#x73B0;&#x6587;&#x672C;&#x5BF9;&#x9F50;&#xFF0C;&#x5373;&#x4E00;&#x4E2A;batch&#x4E2D;&#x7684;&#x53E5;&#x5B50;&#x957F;&#x5EA6;&#x90FD;&#x662F;&#x76F8;&#x540C;&#x7684;&#xFF0C;&#x77ED;&#x53E5;&#x5B50;&#x4F1A;&#x88AB;padding</span>
    EOS_TAG = <span class="hljs-string">&quot;EOS&quot;</span> <span class="hljs-comment">#&#x53E5;&#x5B50;&#x7684;&#x5F00;&#x59CB;</span>
    SOS_TAG = <span class="hljs-string">&quot;SOS&quot;</span> <span class="hljs-comment">#&#x53E5;&#x5B50;&#x7684;&#x7ED3;&#x675F;</span>

    UNK = <span class="hljs-number">0</span>
    PAD = <span class="hljs-number">1</span>
    EOS = <span class="hljs-number">2</span>
    SOS = <span class="hljs-number">3</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        self.dict = {
            self.UNK_TAG : self.UNK,
            self.PAD_TAG : self.PAD,
            self.EOS_TAG : self.EOS,
            self.SOS_TAG : self.SOS
        }
        <span class="hljs-comment">#&#x5F97;&#x5230;&#x5B57;&#x7B26;&#x4E32;&#x548C;&#x6570;&#x5B57;&#x5BF9;&#x5E94;&#x7684;&#x5B57;&#x5178;</span>
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>):
            self.dict[str(i)] = len(self.dict)
        <span class="hljs-comment">#&#x5F97;&#x5230;&#x6570;&#x5B57;&#x548C;&#x5B57;&#x7B26;&#x4E32;&#x5BF9;&#x5E94;&#x7684;&#x5B57;&#x5178;</span>
        self.index2word = dict(zip(self.dict.values(),self.dict.keys()))

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">return</span> len(self.dict)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">transform</span><span class="hljs-params">(self,sequence,max_len=None,add_eos=False)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;
        sequence&#xFF1A;&#x53E5;&#x5B50;
        max_len :&#x53E5;&#x5B50;&#x7684;&#x6700;&#x5927;&#x957F;&#x5EA6;
        add_eos:&#x662F;&#x5426;&#x6DFB;&#x52A0;&#x7ED3;&#x675F;&#x7B26;
        &quot;&quot;&quot;</span>

        sequence_list = list(str(sequence))
        seq_len = len(sequence_list)+<span class="hljs-number">1</span> <span class="hljs-keyword">if</span> add_eos <span class="hljs-keyword">else</span> len(sequence_list)

        <span class="hljs-keyword">if</span> add_eos <span class="hljs-keyword">and</span> max_len <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
            <span class="hljs-keyword">assert</span> max_len&gt;= seq_len, <span class="hljs-string">&quot;max_len &#x9700;&#x8981;&#x5927;&#x4E8E;seq+eos&#x7684;&#x957F;&#x5EA6;&quot;</span>
        _sequence_index = [self.dict.get(i,self.UNK) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sequence_list]
        <span class="hljs-keyword">if</span> add_eos:
            _sequence_index += [self.EOS]
        <span class="hljs-keyword">if</span> max_len <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-keyword">None</span>:
            sequence_index = [self.PAD]*max_len
            sequence_index[:seq_len] =  _sequence_index
            <span class="hljs-keyword">return</span> sequence_index
        <span class="hljs-keyword">else</span>:
            <span class="hljs-keyword">return</span> _sequence_index

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">inverse_transform</span><span class="hljs-params">(self,sequence_index)</span>:</span>
        result = []
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> sequence_index:
            <span class="hljs-keyword">if</span> i==self.EOS:
                <span class="hljs-keyword">break</span>
            result.append(self.index2word.get(int(i),self.UNK_TAG))
        <span class="hljs-keyword">return</span> result
<span class="hljs-comment"># &#x5B9E;&#x4F8B;&#x5316;&#xFF0C;&#x4F9B;&#x540E;&#x7EED;&#x8C03;&#x7528;</span>
num_sequence = NumSequence()

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&apos;__main__&apos;</span>:
    num_sequence = NumSequence()
    print(num_sequence.dict)
    print(num_sequence.index2word)
    print(num_sequence.transform(<span class="hljs-string">&quot;1231230&quot;</span>,add_eos=<span class="hljs-keyword">True</span>))
</code></pre>
<h3 id="23-&#x51C6;&#x5907;&#x6570;&#x636E;&#x96C6;">2.3 &#x51C6;&#x5907;&#x6570;&#x636E;&#x96C6;</h3>
<h4 id="231-&#x51C6;&#x5907;dataset">2.3.1 &#x51C6;&#x5907;<code>Dataset</code></h4>
<p>&#x8FD9;&#x91CC;&#xFF0C;&#x6211;&#x4EEC;&#x4F7F;&#x7528;&#x968F;&#x673A;&#x521B;&#x5EFA;&#x7684;<code>[0,100000000]</code>&#x7684;&#x6574;&#x578B;&#xFF0C;&#x6765;&#x51C6;&#x5907;&#x6570;&#x636E;&#x96C6;</p>
<pre><code class="lang-python"><span class="hljs-keyword">from</span> torch.utils.data <span class="hljs-keyword">import</span> Dataset,DataLoader
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> num_sequence
<span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> config

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">RandomDataset</span><span class="hljs-params">(Dataset)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super(RandomDataset,self).__init__()
        self.total_data_size = <span class="hljs-number">500000</span>
        np.random.seed(<span class="hljs-number">10</span>)
        self.total_data = np.random.randint(<span class="hljs-number">1</span>,<span class="hljs-number">100000000</span>,size=[self.total_data_size])

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__getitem__</span><span class="hljs-params">(self, idx)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;&#x8FD4;&#x56DE;input&#xFF0C;target&#xFF0C;input_length,target_length(&#x771F;&#x5B9E;&#x957F;&#x5EA6;)&quot;&quot;&quot;</span>
        input = str(self.total_data[idx])
        <span class="hljs-keyword">return</span> input, input+ <span class="hljs-string">&quot;0&quot;</span>,len(input),len(input)+<span class="hljs-number">1</span>

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__len__</span><span class="hljs-params">(self)</span>:</span>
        <span class="hljs-keyword">return</span> self.total_data_size
</code></pre>
<p>&#x901A;&#x8FC7;&#x968F;&#x673A;&#x6570;&#x7684;&#x7ED3;&#x679C;&#xFF0C;&#x53EF;&#x4EE5;&#x770B;&#x5230;&#xFF0C;&#x5927;&#x90E8;&#x5206;&#x7684;&#x6570;&#x5B57;&#x957F;&#x5EA6;&#x4E3A;8&#xFF0C;&#x5728;&#x76EE;&#x6807;&#x503C;&#x540E;&#x9762;&#x6DFB;&#x52A0;&#x4E0A;0&#x548C;EOS&#x4E4B;&#x540E;&#xFF0C;&#x6700;&#x5927;&#x957F;&#x5EA6;&#x4E3A;10</p>
<p>&#x6240;&#x4EE5;&#x5E38;&#x89C1;config&#x914D;&#x7F6E;&#x6587;&#x4EF6;&#xFF0C;&#x6DFB;&#x52A0;&#x4E0A;<code>max_len&#xFF1A;&#x6587;&#x672C;&#x6700;&#x5927;&#x957F;&#x5EA6;</code>&#xFF0C;&#x65B9;&#x4FBF;&#x540E;&#x7EED;&#x7684;&#x4FEE;&#x6539;</p>
<h4 id="232-&#x51C6;&#x5907;dataloader">2.3.2 &#x51C6;&#x5907;<code>DataLoader</code></h4>
<p>&#x5728;&#x51C6;&#x5907;<code>DataLoader</code>&#x7684;&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;&#x53EF;&#x4EE5;&#x901A;&#x8FC7;&#x5B9A;&#x4E49;&#x7684;collate_fn&#x6765;&#x5B9E;&#x73B0;&#x5BF9;dataset&#x4E2D;batch&#x6570;&#x636E;&#x7684;&#x5904;&#x7406;</p>
<p>&#x5176;&#x4E2D;&#x9700;&#x8981;&#x6CE8;&#x610F;&#xFF1A;</p>
<ol>
<li>&#x9700;&#x8981;&#x5BF9;batch&#x4E2D;&#x7684;&#x6570;&#x636E;&#x8FDB;&#x884C;&#x6392;&#x5E8F;&#xFF0C;&#x6839;&#x636E;&#x6570;&#x636E;&#x7684;&#x771F;&#x5B9E;&#x957F;&#x5EA6;&#x8FDB;&#x884C;&#x964D;&#x5E8F;&#x6392;&#x5E8F;&#xFF08;&#x540E;&#x9762;&#x9700;&#x8981;&#x7528;&#x5230;&#xFF09;</li>
<li>&#x9700;&#x8981;&#x8C03;&#x7528;<code>&#x6587;&#x672C;&#x5E8F;&#x5217;&#x5316;</code>&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x628A;&#x6587;&#x672C;&#x8FDB;&#x884C;&#x5E8F;&#x5217;&#x5316;&#x7684;&#x64CD;&#x4F5C;&#xFF0C;&#x540C;&#x65F6;target&#x9700;&#x8981;&#x8FDB;&#x884C;<code>add eos</code>&#x7684;&#x64CD;&#x4F5C;</li>
<li>&#x6700;&#x540E;&#x8FD4;&#x56DE;&#x5E8F;&#x5217;&#x7684;LongTensor&#x683C;&#x5F0F;</li>
<li>&#x5728;<code>DataLoader&#x4E2D;&#x6709;drop_last&#x53C2;&#x6570;</code>&#xFF0C;&#x5F53;&#x6570;&#x636E;&#x91CF;&#x65E0;&#x6CD5;&#x88AB;batch_size&#x6574;&#x9664;&#x65F6;&#xFF0C;&#x6700;&#x540E;&#x4E00;&#x4E2A;batch&#x7684;&#x6570;&#x636E;&#x4E2A;&#x6570;&#x548C;&#x4E4B;&#x524D;&#x7684;&#x6570;&#x636E;&#x4E2A;&#x6570;&#x957F;&#x5EA6;&#x4E0D;&#x540C;&#xFF0C;&#x53EF;&#x4EE5;&#x8003;&#x8651;&#x8FDB;&#x884C;&#x5220;&#x9664;</li>
</ol>
<pre><code class="lang-python"><span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">collate_fn</span><span class="hljs-params">(batch)</span>:</span>
    <span class="hljs-comment">#1. &#x5BF9;batch&#x8FDB;&#x884C;&#x6392;&#x5E8F;&#xFF0C;&#x6309;&#x7167;&#x957F;&#x5EA6;&#x4ECE;&#x957F;&#x5230;&#x77ED;&#x7684;&#x987A;&#x5E8F;&#x6392;&#x5E8F;</span>
    batch = sorted(batch,key=<span class="hljs-keyword">lambda</span> x:x[<span class="hljs-number">3</span>],reverse=<span class="hljs-keyword">True</span>)
    input,target,input_length,target_length = zip(*batch)

    <span class="hljs-comment">#2.&#x8FDB;&#x884C;padding&#x7684;&#x64CD;&#x4F5C;</span>
    input = torch.LongTensor([num_sequence.transform(i,max_len=config.max_len) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> input])
    target = torch.LongTensor([num_sequence.transform(i,max_len=config.max_len,add_eos=<span class="hljs-keyword">True</span>) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> target])
    input_length = torch.LongTensor(input_length)
    target_length = torch.LongTensor(target_length)

    <span class="hljs-keyword">return</span> input,target,input_length,target_length

data_loader = DataLoader(dataset=RandomDataset(),batch_size=config.batch_size,collate_fn=collate_fn,drop_last=<span class="hljs-keyword">True</span>)
</code></pre>
<h3 id="24-&#x51C6;&#x5907;&#x7F16;&#x7801;&#x5668;">2.4 &#x51C6;&#x5907;&#x7F16;&#x7801;&#x5668;</h3>
<p>&#x7F16;&#x7801;&#x5668;&#xFF08;encoder&#xFF09;&#x7684;&#x76EE;&#x7684;&#x5C31;&#x662F;&#x4E3A;&#x4E86;&#x5BF9;&#x6587;&#x672C;&#x8FDB;&#x884C;&#x7F16;&#x7801;&#xFF0C;&#x628A;&#x7F16;&#x7801;&#x540E;&#x7684;&#x7ED3;&#x679C;&#x4EA4;&#x7ED9;&#x540E;&#x7EED;&#x7684;&#x7A0B;&#x5E8F;&#x4F7F;&#x7528;&#xFF0C;&#x6240;&#x4EE5;&#x5728;&#x8FD9;&#x91CC;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;<code>Embedding+GRU</code>&#x7684;&#x7ED3;&#x6784;&#x6765;&#x4F7F;&#x7528;&#xFF0C;&#x4F7F;&#x7528;&#x6700;&#x540E;&#x4E00;&#x4E2A;<code>time step</code>&#x7684;&#x8F93;&#x51FA;(<code>hidden state</code>)&#x4F5C;&#x4E3A;<code>&#x53E5;&#x5B50;&#x7684;&#x7F16;&#x7801;&#x7ED3;&#x679C;</code></p>
<p><img src="../images/2.3/Encoder.png" alt=""></p>
<p>&#x6CE8;&#x610F;&#x70B9;&#xFF1A;</p>
<ol>
<li>Embedding&#x548C;GRU&#x7684;&#x53C2;&#x6570;,&#x8FD9;&#x91CC;&#x6211;&#x4EEC;&#x8BA9;GRU&#x4E2D;batch&#x653E;&#x5728;&#x524D;&#x9762;</li>
<li>&#x8F93;&#x51FA;&#x7ED3;&#x679C;&#x7684;&#x5F62;&#x72B6;</li>
<li>&#x5728;LSTM&#x548C;GRU&#x4E2D;&#xFF0C;&#x6BCF;&#x4E2A;<code>time step</code>&#x7684;&#x8F93;&#x5165;&#x4F1A;&#x8FDB;&#x884C;&#x8BA1;&#x7B97;&#xFF0C;&#x5F97;&#x5230;&#x7ED3;&#x679C;&#xFF0C;&#x6574;&#x4E2A;&#x8FC7;&#x7A0B;&#x662F;&#x4E00;&#x4E2A;&#x548C;&#x53E5;&#x5B50;&#x957F;&#x5EA6;&#x76F8;&#x5173;&#x7684;&#x4E00;&#x4E2A;&#x5FAA;&#x73AF;&#xFF0C;&#x624B;&#x52A8;&#x5B9E;&#x73B0;&#x901F;&#x5EA6;&#x8F83;&#x6162;<ol>
<li>pytorch&#x4E2D;&#x5B9E;&#x73B0;&#x4E86;<code>nn.utils.rnn.pack_padded_sequence</code> &#x5BF9;padding&#x540E;&#x7684;&#x53E5;&#x5B50;&#x8FDB;&#x884C;&#x6253;&#x5305;&#x7684;&#x64CD;&#x4F5C;&#x80FD;&#x591F;&#x66F4;&#x5FEB;&#x83B7;&#x5F97;LSTM or GRU&#x7684;&#x7ED3;&#x679C;</li>
<li>&#x540C;&#x65F6;&#x5B9E;&#x73B0;&#x4E86;<code>nn.utils.rnn.pad_packed_sequence</code>&#x5BF9;&#x6253;&#x5305;&#x7684;&#x5185;&#x5BB9;&#x8FDB;&#x884C;&#x89E3;&#x5305;&#x7684;&#x64CD;&#x4F5C;</li>
</ol>
</li>
<li><code>nn.utils.rnn.pack_padded_sequence</code>&#x4F7F;&#x7528;&#x8FC7;&#x7A0B;&#x4E2D;&#x9700;&#x8981;&#x5BF9;batch&#x4E2D;&#x7684;&#x5185;&#x5BB9;&#x6309;&#x7167;&#x53E5;&#x5B50;&#x7684;&#x957F;&#x5EA6;<strong>&#x964D;&#x5E8F;&#x6392;&#x5E8F;</strong></li>
</ol>
<p>&#x5B9E;&#x73B0;&#x4EE3;&#x7801;&#x5982;&#x4E0B;&#xFF1A;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> num_sequence
<span class="hljs-keyword">import</span> config


<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NumEncoder</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super(NumEncoder,self).__init__()
        self.vocab_size = len(num_sequence)
        self.dropout = config.dropout
        self.embedding = nn.Embedding(num_embeddings=self.vocab_size,embedding_dim=config.embedding_dim,padding_idx=num_sequence.PAD)
        self.gru = nn.GRU(input_size=config.embedding_dim,
                          hidden_size=config.hidden_size,
                          num_layers=<span class="hljs-number">1</span>,
                          batch_first=<span class="hljs-keyword">True</span>)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, input,input_length)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;
        input:[batch_size,max_len]
        input_length:[batch_size]
        &quot;&quot;&quot;</span>
        embeded = self.embedding(input) <span class="hljs-comment">#[batch_size,max_len , embedding_dim]</span>

        <span class="hljs-comment">#&#x5BF9;&#x6587;&#x672C;&#x5BF9;&#x9F50;&#x4E4B;&#x540E;&#x7684;&#x53E5;&#x5B50;&#x8FDB;&#x884C;&#x6253;&#x5305;&#xFF0C;&#x80FD;&#x591F;&#x52A0;&#x901F;&#x5728;LSTM or GRU&#x4E2D;&#x7684;&#x8BA1;&#x7B97;&#x8FC7;&#x7A0B;</span>
        embeded = nn.utils.rnn.pack_padded_sequence(embeded,lengths=input_length,batch_first=<span class="hljs-keyword">True</span>)

        <span class="hljs-comment">#hidden:[1,batch_size,vocab_size]</span>
        out,hidden = self.gru(embeded)

        <span class="hljs-comment">#&#x5BF9;&#x524D;&#x9762;&#x6253;&#x5305;&#x540E;&#x7684;&#x7ED3;&#x679C;&#x518D;&#x8FDB;&#x884C;&#x89E3;&#x5305;</span>
        out,outputs_length = nn.utils.rnn.pad_packed_sequence(out,batch_first=<span class="hljs-keyword">True</span>,padding_value=num_sequence.PAD)
        <span class="hljs-comment"># out [batch_size,seq_len,hidden_size]</span>
        <span class="hljs-keyword">return</span> out,hidden
</code></pre>
<h3 id="25-&#x5B9E;&#x73B0;&#x89E3;&#x7801;&#x5668;">2.5 &#x5B9E;&#x73B0;&#x89E3;&#x7801;&#x5668;</h3>
<p>&#x52A0;&#x7801;&#x5668;&#x4E3B;&#x8981;&#x8D1F;&#x8D23;&#x5B9E;&#x73B0;&#x5BF9;&#x7F16;&#x7801;&#x4E4B;&#x540E;&#x7ED3;&#x679C;&#x7684;&#x5904;&#x7406;&#xFF0C;&#x5F97;&#x5230;&#x9884;&#x6D4B;&#x503C;&#xFF0C;&#x4E3A;&#x540E;&#x7EED;&#x8BA1;&#x7B97;&#x635F;&#x5931;&#x505A;&#x51C6;&#x5907;</p>
<p>&#x6B64;&#x65F6;&#x9700;&#x8981;&#x601D;&#x8003;&#xFF1A;</p>
<ol>
<li><p>&#x4F7F;&#x7528;&#x4EC0;&#x4E48;&#x6837;&#x7684;&#x635F;&#x5931;&#x51FD;&#x6570;&#xFF0C;&#x9884;&#x6D4B;&#x503C;&#x9700;&#x8981;&#x662F;&#x4EC0;&#x4E48;&#x683C;&#x5F0F;&#x7684;</p>
<ul>
<li>&#x7ED3;&#x5408;&#x4E4B;&#x524D;&#x7684;&#x7ECF;&#x9A8C;&#xFF0C;&#x6211;&#x4EEC;&#x53EF;&#x4EE5;&#x7406;&#x89E3;&#x4E3A;&#x5F53;&#x524D;&#x7684;&#x95EE;&#x9898;&#x662F;&#x4E00;&#x4E2A;&#x5206;&#x7C7B;&#x7684;&#x95EE;&#x9898;&#xFF0C;&#x5373;&#x6BCF;&#x6B21;&#x7684;&#x8F93;&#x51FA;&#x5176;&#x5B9E;&#x5BF9;&#x9009;&#x62E9;&#x4E00;&#x4E2A;&#x6982;&#x7387;&#x6700;&#x5927;&#x7684;&#x8BCD;</li>
<li>&#x771F;&#x5B9E;&#x503C;&#x7684;&#x5F62;&#x72B6;&#x662F;<code>[batch_size,max_len]</code>&#xFF0C;&#x4ECE;&#x800C;&#x6211;&#x4EEC;&#x77E5;&#x9053;&#x8F93;&#x51FA;&#x7684;&#x7ED3;&#x679C;&#x9700;&#x8981;&#x662F;&#x4E00;&#x4E2A;<code>[batch_size,max_len,vocab_size]</code>&#x7684;&#x5F62;&#x72B6;</li>
<li>&#x5373;&#x9884;&#x6D4B;&#x503C;&#x7684;&#x6700;&#x540E;&#x4E00;&#x4E2A;&#x7EF4;&#x5EA6;&#x8FDB;&#x884C;&#x8BA1;&#x7B97;log_softmax,&#x7136;&#x540E;&#x548C;&#x771F;&#x5B9E;&#x503C;&#x8FDB;&#x884C;&#x76F8;&#x4E58;&#xFF0C;&#x4ECE;&#x800C;&#x5F97;&#x5230;&#x635F;&#x5931;</li>
</ul>
</li>
<li><p>&#x5982;&#x4F55;&#x628A;&#x7F16;&#x7801;&#x7ED3;&#x679C;<code>[1,batch_size,hidden_size]</code>&#x8FDB;&#x884C;&#x64CD;&#x4F5C;&#xFF0C;&#x5F97;&#x5230;&#x9884;&#x6D4B;&#x503C;&#x3002;&#x89E3;&#x7801;&#x5668;&#x4E5F;&#x662F;&#x4E00;&#x4E2A;RNN&#xFF0C;&#x5373;&#x4E5F;&#x53EF;&#x4EE5;&#x4F7F;&#x7528;LSTM or GRU&#x7684;&#x7ED3;&#x6784;&#xFF0C;&#x6240;&#x4EE5;&#x5728;&#x89E3;&#x7801;&#x5668;&#x4E2D;&#xFF1A;</p>
<ul>
<li><p>&#x901A;&#x8FC7;&#x5FAA;&#x73AF;&#xFF0C;&#x6BCF;&#x6B21;&#x8BA1;&#x7B97;&#x7684;&#x4E00;&#x4E2A;time step&#x7684;&#x5185;&#x5BB9;</p>
</li>
<li><p>&#x7F16;&#x7801;&#x5668;&#x7684;&#x7ED3;&#x679C;&#x4F5C;&#x4E3A;&#x521D;&#x59CB;&#x7684;&#x9690;&#x5C42;&#x72B6;&#x6001;&#xFF0C;&#x5B9A;&#x4E49;&#x4E00;&#x4E2A;<code>[batch_size,1]</code>&#x7684;&#x5168;&#x4E3A;<code>SOS</code>&#x7684;&#x6570;&#x636E;&#x4F5C;&#x4E3A;&#x6700;&#x5F00;&#x59CB;&#x7684;&#x8F93;&#x5165;&#xFF0C;&#x544A;&#x8BC9;&#x89E3;&#x7801;&#x5668;&#xFF0C;&#x8981;&#x5F00;&#x59CB;&#x5DE5;&#x4F5C;&#x4E86;</p>
</li>
<li>&#x901A;&#x8FC7;&#x89E3;&#x7801;&#x5668;&#x9884;&#x6D4B;&#x4E00;&#x4E2A;&#x8F93;&#x51FA;<code>[batch_size,hidden_size]</code>(&#x4F1A;&#x8FDB;&#x884C;&#x5F62;&#x72B6;&#x7684;&#x8C03;&#x6574;&#x4E3A;<code>[batch_size,vocab_size]</code>)&#xFF0C;&#x628A;&#x8FD9;&#x4E2A;&#x8F93;&#x51FA;&#x4F5C;&#x4E3A;&#x8F93;&#x5165;&#x518D;&#x4F7F;&#x7528;&#x89E3;&#x7801;&#x5668;&#x8FDB;&#x884C;&#x89E3;&#x7801;</li>
<li>&#x4E0A;&#x8FF0;&#x662F;&#x4E00;&#x4E2A;&#x5FAA;&#x73AF;&#xFF0C;&#x5FAA;&#x73AF;&#x6B21;&#x6570;&#x5C31;&#x662F;&#x53E5;&#x5B50;&#x7684;&#x6700;&#x5927;&#x957F;&#x5EA6;&#xFF0C;&#x90A3;&#x4E48;&#x5C31;&#x53EF;&#x4EE5;&#x5F97;&#x5230;<code>max_len</code>&#x4E2A;&#x8F93;&#x51FA;</li>
<li>&#x628A;&#x6240;&#x6709;&#x8F93;&#x51FA;&#x7684;&#x7ED3;&#x679C;&#x8FDB;&#x884C;concate&#xFF0C;&#x5F97;&#x5230;<code>[batch_size,max_len,vocab_size]</code></li>
</ul>
</li>
<li><p>&#x5728;RNN&#x7684;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;&#x4F7F;&#x7528;&#x524D;&#x4E00;&#x4E2A;&#x9884;&#x6D4B;&#x7684;&#x7ED3;&#x679C;&#x4F5C;&#x4E3A;&#x4E0B;&#x4E00;&#x4E2A;step&#x7684;&#x8F93;&#x5165;&#xFF0C;&#x53EF;&#x80FD;&#x4F1A;&#x5BFC;&#x81F4;<code>&#x4E00;&#x6B65;&#x9519;&#xFF0C;&#x6B65;&#x6B65;&#x9519;&#x7684;&#x7ED3;&#x679C;</code>&#xFF0C;&#x5982;&#x679C;&#x63D0;&#x9AD8;&#x6A21;&#x578B;&#x7684;&#x6536;&#x655B;&#x901F;&#x5EA6;&#xFF1F;</p>
<ul>
<li>&#x53EF;&#x4EE5;&#x8003;&#x8651;&#x5728;&#x8BAD;&#x7EC3;&#x7684;&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;&#x628A;&#x771F;&#x5B9E;&#x503C;&#x4F5C;&#x4E3A;&#x4E0B;&#x4E00;&#x6B65;&#x7684;&#x8F93;&#x5165;&#xFF0C;&#x8FD9;&#x6837;&#x53EF;&#x4EE5;&#x907F;&#x514D;<code>&#x6B65;&#x6B65;&#x9519;&#x7684;&#x5C40;&#x9762;</code></li>
<li>&#x540C;&#x65F6;&#x5728;&#x4F7F;&#x7528;&#x771F;&#x5B9E;&#x503C;&#x7684;&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;&#x4ECD;&#x7136;&#x4F7F;&#x7528;&#x9884;&#x6D4B;&#x503C;&#x4F5C;&#x4E3A;&#x4E0B;&#x4E00;&#x6B65;&#x7684;&#x8F93;&#x5165;&#xFF0C;&#x4E24;&#x79CD;&#x8F93;&#x5165;&#x968F;&#x673A;&#x4F7F;&#x7528;</li>
<li>&#x4E0A;&#x8FF0;&#x8FD9;&#x79CD;&#x673A;&#x5236;&#x6211;&#x4EEC;&#x628A;&#x5B83;&#x79F0;&#x4E3A;<code>Teacher forcing</code>&#xFF0C;&#x5C31;&#x50CF;&#x662F;&#x4E00;&#x4E2A;&#x6307;&#x5BFC;&#x8001;&#x5E08;&#xFF0C;&#x5728;&#x6BCF;&#x4E00;&#x6B65;&#x90FD;&#x4F1A;&#x5BF9;&#x6211;&#x4EEC;&#x7684;&#x884C;&#x4E3A;&#x8FDB;&#x884C;&#x7EA0;&#x504F;&#xFF0C;&#x4ECE;&#x800C;&#x8FBE;&#x5230;&#x5728;&#x591A;&#x6B21;&#x8BAD;&#x7EC3;&#x4E4B;&#x540E;&#x80FD;&#x591F;&#x9700;&#x8981;&#x5176;&#x4E2D;&#x7684;&#x89C4;&#x5F8B;</li>
<li><img src="../images/2.3/teacher forcing.jpg" alt=""></li>
</ul>
</li>
</ol>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">import</span> config
<span class="hljs-keyword">import</span> random
<span class="hljs-keyword">import</span> torch.nn.functional <span class="hljs-keyword">as</span> F
<span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> num_sequence

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">NumDecoder</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self)</span>:</span>
        super(NumDecoder,self).__init__()
        self.max_seq_len = config.max_len
        self.vocab_size = len(num_sequence)
        self.embedding_dim = config.embedding_dim
        self.dropout = config.dropout

        self.embedding = nn.Embedding(num_embeddings=self.vocab_size,embedding_dim=self.embedding_dim,padding_idx=num_sequence.PAD)
        self.gru = nn.GRU(input_size=self.embedding_dim,
                          hidden_size=config.hidden_size,
                          num_layers=<span class="hljs-number">1</span>,
                          batch_first=<span class="hljs-keyword">True</span>,
                          dropout=self.dropout)
        self.log_softmax = nn.LogSoftmax()

        self.fc = nn.Linear(config.hidden_size,self.vocab_size)

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, encoder_hidden,target,target_length)</span>:</span>
        <span class="hljs-comment"># encoder_hidden [batch_size,hidden_size]</span>
        <span class="hljs-comment"># target [batch_size,max_len]</span>

        <span class="hljs-comment">#&#x521D;&#x59CB;&#x7684;&#x5168;&#x4E3A;SOS&#x7684;&#x8F93;&#x5165;</span>
        decoder_input = torch.LongTensor([[num_sequence.SOS]]*config.batch_size)

        <span class="hljs-comment">#&#x89E3;&#x7801;&#x5668;&#x7684;&#x8F93;&#x51FA;&#xFF0C;&#x7528;&#x6765;&#x540E;&#x4FDD;&#x5B58;&#x6240;&#x6709;&#x7684;&#x8F93;&#x51FA;&#x7ED3;&#x679C;</span>
        decoder_outputs = torch.zeros(config.batch_size,config.max_len,self.vocab_size) 

        decoder_hidden = encoder_hidden <span class="hljs-comment">#[batch_size,hidden_size]</span>

        <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> range(config.max_len):
            decoder_output_t , decoder_hidden = self.forward_step(decoder_input,decoder_hidden)

            <span class="hljs-comment">#&#x5728;&#x4E0D;&#x540C;&#x7684;time step&#x4E0A;&#x8FDB;&#x884C;&#x590D;&#x5236;&#xFF0C;decoder_output_t [batch_size,vocab_size]</span>
            decoder_outputs[:,t,:] = decoder_output_t

            <span class="hljs-comment">#&#x5728;&#x8BAD;&#x7EC3;&#x7684;&#x8FC7;&#x7A0B;&#x4E2D;&#xFF0C;&#x4F7F;&#x7528; teacher forcing&#xFF0C;&#x8FDB;&#x884C;&#x7EA0;&#x504F;</span>
            use_teacher_forcing = random.random() &gt; <span class="hljs-number">0.5</span>
            <span class="hljs-keyword">if</span> use_teacher_forcing:
                <span class="hljs-comment">#&#x4E0B;&#x4E00;&#x6B21;&#x7684;&#x8F93;&#x5165;&#x4F7F;&#x7528;&#x771F;&#x5B9E;&#x503C;</span>
                decoder_input =target[:,t].unsqueeze(<span class="hljs-number">1</span>)  <span class="hljs-comment">#[batch_size,1]</span>
            <span class="hljs-keyword">else</span>:
                <span class="hljs-comment">#&#x4F7F;&#x7528;&#x9884;&#x6D4B;&#x503C;&#xFF0C;topk&#x4E2D;k=1&#xFF0C;&#x5373;&#x83B7;&#x53D6;&#x6700;&#x540E;&#x4E00;&#x4E2A;&#x7EF4;&#x5EA6;&#x7684;&#x6700;&#x5927;&#x7684;&#x4E00;&#x4E2A;&#x503C;</span>
                value, index = torch.topk(decoder_output_t, <span class="hljs-number">1</span>) <span class="hljs-comment"># index [batch_size,1]</span>
                decoder_input = index
        <span class="hljs-keyword">return</span> decoder_outputs,decoder_hidden

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward_step</span><span class="hljs-params">(self,decoder_input,decoder_hidden)</span>:</span>
        <span class="hljs-string">&quot;&quot;&quot;
        :param decoder_input:[batch_size,1]
        :param decoder_hidden: [1,batch_size,hidden_size]
        :return: out:[batch_size,vocab_size],decoder_hidden:[1,batch_size,didden_size]
        &quot;&quot;&quot;</span>
        embeded = self.embedding(decoder_input)  <span class="hljs-comment">#embeded: [batch_size,1 , embedding_dim]</span>

        out,decoder_hidden = self.gru(embeded,decoder_hidden) <span class="hljs-comment">#out [1, batch_size, hidden_size]</span>

           out = out.squeeze(<span class="hljs-number">0</span>) <span class="hljs-comment">#&#x53BB;&#x9664;&#x7B2C;0&#x7EF4;&#x5EA6;&#x7684;1</span>
        <span class="hljs-comment">#&#x8FDB;&#x884C;&#x5168;&#x8FDE;&#x63A5;&#x5F62;&#x72B6;&#x53D8;&#x5316;&#xFF0C;&#x540C;&#x65F6;&#x8FDB;&#x884C;&#x6C42;&#x53D6;log_softmax</span>
        out = F.log_softmax(self.fc(out),dim=<span class="hljs-number">-1</span>)<span class="hljs-comment">#out [batch_Size,1, vocab_size]</span>
        out = out.squeeze(<span class="hljs-number">1</span>)
        <span class="hljs-keyword">return</span> out,decoder_hidden
</code></pre>
<h3 id="26-&#x5B8C;&#x6210;seq2seq&#x6A21;&#x578B;">2.6 &#x5B8C;&#x6210;seq2seq&#x6A21;&#x578B;</h3>
<p>&#x8C03;&#x7528;&#x4E4B;&#x524D;&#x7684;encoder&#x548C;decoder&#xFF0C;&#x5B8C;&#x6210;&#x6A21;&#x578B;&#x7684;&#x642D;&#x5EFA;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Seq2Seq</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,encoder,decoder)</span>:</span>
        super(Seq2Seq,self).__init__()
        self.encoder = encoder
        self.decoder = decoder

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, input,target,input_length,target_length)</span>:</span>
        <span class="hljs-comment">#&#x8FDB;&#x884C;&#x7F16;&#x7801;</span>
        encoder_outputs,encoder_hidden = self.encoder(input,input_length)
        <span class="hljs-comment">#&#x8FDB;&#x884C;&#x89E3;&#x7801;</span>
        decoder_outputs,decoder_hidden = self.decoder(encoder_hidden,target,target_length)
        <span class="hljs-keyword">return</span> decoder_outputs,decoder_hidden
</code></pre>
<h3 id="27-&#x5B8C;&#x6210;&#x8BAD;&#x7EC3;&#x903B;&#x8F91;">2.7 &#x5B8C;&#x6210;&#x8BAD;&#x7EC3;&#x903B;&#x8F91;</h3>
<p>&#x601D;&#x8DEF;&#x6D41;&#x7A0B;&#x548C;&#x4E4B;&#x524D;&#x76F8;&#x540C;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> config
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">from</span> encoder <span class="hljs-keyword">import</span> NumEncoder
<span class="hljs-keyword">from</span> decoder <span class="hljs-keyword">import</span> NumDecoder
<span class="hljs-keyword">from</span> seq2seq <span class="hljs-keyword">import</span> Seq2Seq
<span class="hljs-keyword">from</span> dataset <span class="hljs-keyword">import</span> data_loader <span class="hljs-keyword">as</span> train_dataloader
<span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> num_sequence



encoder = NumEncoder()
decoder = NumDecoder()
model = Seq2Seq(encoder,decoder)
print(model)

<span class="hljs-comment">#&#x81EA;&#x5B9A;&#x4E49;&#x521D;&#x59CB;&#x5316;&#x53C2;&#x6570;</span>
<span class="hljs-comment">#for name, param in model.named_parameters():</span>
<span class="hljs-comment">#    if &apos;bias&apos; in name:</span>
<span class="hljs-comment">#        torch.nn.init.constant_(param, 0.0)</span>
<span class="hljs-comment">#    elif &apos;weight&apos; in name:</span>
<span class="hljs-comment">#        torch.nn.init.xavier_normal_(param)</span>

<span class="hljs-comment"># model.load_state_dict(torch.load(&quot;model/seq2seq_model.pkl&quot;))</span>
optimizer =  optim.Adam(model.parameters())
<span class="hljs-comment"># optimizer.load_state_dict(torch.load(&quot;model/seq2seq_optimizer.pkl&quot;))</span>
criterion= nn.NLLLoss(ignore_index=num_sequence.PAD,reduction=<span class="hljs-string">&quot;mean&quot;</span>)

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">get_loss</span><span class="hljs-params">(decoder_outputs,target)</span>:</span>
    <span class="hljs-comment">#&#x5F88;&#x591A;&#x65F6;&#x5019;&#x5982;&#x679C;tensor&#x8FDB;&#x884C;&#x4E86;&#x8F6C;&#x7F6E;&#x7B49;&#x64CD;&#x4F5C;&#xFF0C;&#x76F4;&#x63A5;&#x8C03;&#x7528;view&#x8FDB;&#x884C;&#x5F62;&#x72B6;&#x7684;&#x4FEE;&#x6539;&#x662F;&#x65E0;&#x6CD5;&#x6210;&#x529F;&#x7684;</span>
    <span class="hljs-comment">#target = target.contiguous().view(-1) #[batch_size*max_len]</span>
    target = target.view(<span class="hljs-number">-1</span>)
    decoder_outputs = decoder_outputs.view(config.batch_size*config.max_len,<span class="hljs-number">-1</span>)
    <span class="hljs-keyword">return</span> criterion(decoder_outputs,target)


<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">train</span><span class="hljs-params">(epoch)</span>:</span>
    <span class="hljs-keyword">for</span> idx,(input,target,input_length,target_len) <span class="hljs-keyword">in</span> enumerate(train_dataloader):
        optimizer.zero_grad()
        <span class="hljs-comment">##[seq_len,batch_size,vocab_size] [batch_size,seq_len]</span>
        decoder_outputs,decoder_hidden = model(input,target,input_length,target_len)
        loss = get_loss(decoder_outputs,target)
        loss.backward()
        optimizer.step()

        print(<span class="hljs-string">&apos;Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}&apos;</span>.format(
            epoch, idx * len(input), len(train_dataloader.dataset),
                   <span class="hljs-number">100.</span> * idx / len(train_dataloader), loss.item()))

        torch.save(model.state_dict(), <span class="hljs-string">&quot;model/seq2seq_model.pkl&quot;</span>)
        torch.save(optimizer.state_dict(), <span class="hljs-string">&apos;model/seq2seq_optimizer.pkl&apos;</span>)

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&apos;__main__&apos;</span>:
    <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(<span class="hljs-number">10</span>):
        train(i)
</code></pre>
<h3 id="28-&#x5B8C;&#x6210;&#x6A21;&#x578B;&#x8BC4;&#x4F30;&#x903B;&#x8F91;">2.8 &#x5B8C;&#x6210;&#x6A21;&#x578B;&#x8BC4;&#x4F30;&#x903B;&#x8F91;</h3>
<p>&#x5B8C;&#x6210;&#x8BC4;&#x4F30;&#x903B;&#x8F91;&#xFF0C;&#x548C;decoder&#x4E2D;&#x7684;&#x8BAD;&#x7EC3;&#x8FC7;&#x7A0B;&#x7A0D;&#x5FAE;&#x4E0D;&#x540C;&#xFF0C;&#x53EF;&#x4EE5;&#x5728;&#x5176;&#x4E2D;&#x65B0;&#x5EFA;<code>evaluation</code>&#x7684;&#x65B9;&#x6CD5;&#xFF0C;&#x4F20;&#x5165;<code>encoder_hidden</code>&#xFF0C;&#x5F97;&#x5230;&#x9884;&#x6D4B;&#x7684;&#x7ED3;&#x679C;</p>
<pre><code class="lang-python">    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">evaluation</span><span class="hljs-params">(self,encoder_hidden)</span>:</span> <span class="hljs-comment">#[1, 20, 14]</span>
        batch_size = encoder_hidden.size(<span class="hljs-number">1</span>) <span class="hljs-comment">#&#x8BC4;&#x4F30;&#x7684;&#x65F6;&#x5019;&#x548C;&#x8BAD;&#x7EC3;&#x7684;batch_size&#x4E0D;&#x540C;&#xFF0C;&#x4E0D;&#x9002;&#x7528;config&#x7684;&#x914D;&#x7F6E;</span>

        decoder_input = torch.LongTensor([[num_sequence.SOS] * batch_size])
        decoder_outputs = torch.zeros(batch_size,config.max_len, self.vocab_size)  <span class="hljs-comment"># [batch_size&#xFF0C;seq_len,vocab_size]</span>
        decoder_hidden = encoder_hidden

        <span class="hljs-comment">#&#x8BC4;&#x4F30;&#xFF0C;&#x4E0D;&#x518D;&#x4F7F;&#x7528;teacher forcing&#xFF0C;&#x5B8C;&#x5168;&#x4F7F;&#x7528;&#x9884;&#x6D4B;&#x503C;&#x4F5C;&#x4E3A;&#x4E0B;&#x4E00;&#x6B21;&#x7684;&#x8F93;&#x5165;</span>
        <span class="hljs-keyword">for</span> t <span class="hljs-keyword">in</span> range(config.max_len):
            decoder_output_t, decoder_hidden = self.forward_step(decoder_input, decoder_hidden)
            decoder_outputs[:,t,:] = decoder_output_t
            value, index = torch.topk(decoder_output_t, <span class="hljs-number">1</span>)  <span class="hljs-comment"># index [20,1]</span>
            decoder_input = index.transpose(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>)

        <span class="hljs-comment">#&#x83B7;&#x53D6;&#x8F93;&#x51FA;&#x7684;id</span>
        decoder_indices = []  <span class="hljs-comment">#[[1,2,4],[23,3,2]]</span>
        <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> range(config.max_len):
            value,index = torch.topk(decoder_outputs[:,i,:],k=<span class="hljs-number">1</span>,dim=<span class="hljs-number">-1</span>)
            decoder_indices.append(index.view(<span class="hljs-number">-1</span>).numpy())
        <span class="hljs-comment">#transpose &#x8C03;&#x6574;&#x4E3A;&#x6309;&#x53E5;&#x5B50;&#x8F93;&#x51FA;</span>
        decoder_indices = np.array(decoder_indices).transpose() 
        <span class="hljs-keyword">return</span> decoder_indices
</code></pre>
<p>&#x4E4B;&#x540E;&#x518D;seq2seq&#x7684;model&#x4E2D;&#xFF0C;&#x6DFB;&#x52A0;<code>evaluation</code>&#x7684;&#x903B;&#x8F91;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn

<span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">Seq2Seq</span><span class="hljs-params">(nn.Module)</span>:</span>
    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">__init__</span><span class="hljs-params">(self,encoder,decoder)</span>:</span>
        super(Seq2Seq,self).__init__()
        self.encoder = encoder
        self.decoder = decoder

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">forward</span><span class="hljs-params">(self, input,target,input_length,target_length)</span>:</span>
        encoder_outputs,encoder_hidden = self.encoder(input,input_length)
        decoder_outputs,decoder_hidden = self.decoder(encoder_hidden,target,target_length)
        <span class="hljs-keyword">return</span> decoder_outputs,decoder_hidden

    <span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">evaluation</span><span class="hljs-params">(self,inputs,input_length)</span>:</span>
        encoder_outputs,encoder_hidden = self.encoder(inputs,input_length)
        decoded_sentence = self.decoder.evaluation(encoder_hidden)
        <span class="hljs-keyword">return</span> decoded_sentence
</code></pre>
<p>&#x521B;&#x5EFA;<code>eval.py</code>&#xFF0C;&#x5B8C;&#x6210;&#x6A21;&#x578B;&#x8BC4;&#x4F30;&#x7684;&#x903B;&#x8F91;</p>
<pre><code class="lang-python"><span class="hljs-keyword">import</span> torch
<span class="hljs-keyword">import</span> config
<span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> optim
<span class="hljs-keyword">import</span> torch.nn <span class="hljs-keyword">as</span> nn
<span class="hljs-keyword">from</span> encoder <span class="hljs-keyword">import</span> NumEncoder
<span class="hljs-keyword">from</span> decoder <span class="hljs-keyword">import</span> NumDecoder
<span class="hljs-keyword">from</span> seq2seq <span class="hljs-keyword">import</span> Seq2Seq
<span class="hljs-keyword">from</span> dataset <span class="hljs-keyword">import</span> data_loader <span class="hljs-keyword">as</span> train_dataloader
<span class="hljs-keyword">from</span> word_sequence <span class="hljs-keyword">import</span> num_sequence
<span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np
<span class="hljs-keyword">import</span> random



encoder = NumEncoder()
decoder = NumDecoder()
model = Seq2Seq(encoder,decoder)
model.load_state_dict(torch.load(<span class="hljs-string">&quot;model/seq2seq_model.pkl&quot;</span>))

<span class="hljs-function"><span class="hljs-keyword">def</span> <span class="hljs-title">evalaute</span><span class="hljs-params">()</span>:</span>
    data = [str(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> np.random.randint(<span class="hljs-number">0</span>, <span class="hljs-number">100000000</span>, [<span class="hljs-number">10</span>])]
    data = sorted(data,key=<span class="hljs-keyword">lambda</span> x:len(x),reverse=<span class="hljs-keyword">True</span>)
    print(data)

    _data_length = torch.LongTensor([len(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data])
    _data = torch.LongTensor([num_sequence.transform(i,max_len=config.max_len) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> data])
    output = seq2seq.evaluate(_data,_data_length)
    print([num_sequence.inverse_transform(i) <span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> output])

<span class="hljs-keyword">if</span> __name__ == <span class="hljs-string">&apos;__main__&apos;</span>:
    evalaute()
</code></pre>
<p>&#x5728;model&#x8BAD;&#x7EC3;&#x4E00;&#x4E2A;epoch&#x4E4B;&#x540E;&#xFF0C;loss&#x5DF2;&#x7ECF;&#x5F88;&#x4F4E;&#x4E86;,&#x8BC4;&#x4F30;&#x8F93;&#x51FA;&#x5982;&#x4E0B;&#xFF08;&#x4E3A;True&#x8868;&#x793A;&#x9884;&#x6D4B;&#x6B63;&#x786E;&#xFF09;&#xFF1A;</p>
<pre><code class="lang-python"><span class="hljs-number">39304187</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">393041870</span> <span class="hljs-keyword">True</span>
<span class="hljs-number">41020882</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">410208820</span> <span class="hljs-keyword">True</span>
<span class="hljs-number">85784317</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">857843170</span> <span class="hljs-keyword">True</span>
<span class="hljs-number">1394232</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">13942320</span> <span class="hljs-keyword">True</span>
<span class="hljs-number">44548446</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">445484460</span> <span class="hljs-keyword">True</span>
<span class="hljs-number">49457730</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">494577300</span> <span class="hljs-keyword">True</span>
<span class="hljs-number">82451872</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">824518720</span> <span class="hljs-keyword">True</span>
<span class="hljs-number">64380958</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">643809580</span> <span class="hljs-keyword">True</span>
<span class="hljs-number">97501723</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">975017230</span> <span class="hljs-keyword">True</span>
<span class="hljs-number">21656800</span> &gt;&gt;&gt;&gt;&gt; <span class="hljs-number">216568000</span> <span class="hljs-keyword">True</span>
</code></pre>
<p>&#x5B8C;&#x6574;&#x4EE3;&#x7801;&#x53C2;&#x8003;&#xFF1A;<a href="https://github.com/SpringMagnolia/PytorchTutorial/tree/master/seq2seq" target="_blank">https://github.com/SpringMagnolia/PytorchTutorial/tree/master/seq2seq</a></p>

                                
                                </section>
                            
    </div>
    <div class="search-results">
        <div class="has-results">
            
            <h1 class="search-results-title"><span class='search-results-count'></span> results matching "<span class='search-query'></span>"</h1>
            <ul class="search-results-list"></ul>
            
        </div>
        <div class="no-results">
            
            <h1 class="search-results-title">No results matching "<span class='search-query'></span>"</h1>
            
        </div>
    </div>
</div>

                        </div>
                    </div>
                
            </div>

            
                
                <a href="2.3.1 闲聊机器人的介绍.html" class="navigation navigation-prev " aria-label="Previous page: 闲聊机器人的介绍">
                    <i class="fa fa-angle-left"></i>
                </a>
                
                
                <a href="2.3.3 seq2seq实现闲聊机器人.html" class="navigation navigation-next " aria-label="Next page: seq2seq实现闲聊机器人">
                    <i class="fa fa-angle-right"></i>
                </a>
                
            
        
    </div>

    <script>
        var gitbook = gitbook || [];
        gitbook.push(function() {
            gitbook.page.hasChanged({"page":{"title":"seq2seq模型的原理","level":"1.3.3.2","depth":3,"next":{"title":"seq2seq实现闲聊机器人","level":"1.3.3.3","depth":3,"path":"2.3 Seq2Seq模型和闲聊机器人/2.3.3 seq2seq实现闲聊机器人.md","ref":"./2.3 Seq2Seq模型和闲聊机器人/2.3.3 seq2seq实现闲聊机器人.md","articles":[]},"previous":{"title":"闲聊机器人的介绍","level":"1.3.3.1","depth":3,"path":"2.3 Seq2Seq模型和闲聊机器人/2.3.1 闲聊机器人的介绍.md","ref":"./2.3 Seq2Seq模型和闲聊机器人/2.3.1 闲聊机器人的介绍.md","articles":[]},"dir":"ltr"},"config":{"gitbook":"*","theme":"default","variables":{},"plugins":["livereload"],"pluginsConfig":{"livereload":{},"highlight":{},"search":{},"lunr":{"maxIndexSize":1000000,"ignoreSpecialCharacters":false},"sharing":{"facebook":true,"twitter":true,"google":false,"weibo":false,"instapaper":false,"vk":false,"all":["facebook","google","twitter","weibo","instapaper"]},"fontsettings":{"theme":"white","family":"sans","size":2},"theme-default":{"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"},"showLevel":false}},"structure":{"langs":"LANGS.md","readme":"README.md","glossary":"GLOSSARY.md","summary":"SUMMARY.md"},"pdf":{"pageNumbers":true,"fontSize":12,"fontFamily":"Arial","paperSize":"a4","chapterMark":"pagebreak","pageBreaksBefore":"/","margin":{"right":62,"left":62,"top":56,"bottom":56}},"styles":{"website":"styles/website.css","pdf":"styles/pdf.css","epub":"styles/epub.css","mobi":"styles/mobi.css","ebook":"styles/ebook.css","print":"styles/print.css"}},"file":{"path":"2.3 Seq2Seq模型和闲聊机器人/2.3.2 seq2seq模型的原理.md","mtime":"2019-05-05T10:14:55.989Z","type":"markdown"},"gitbook":{"version":"3.2.3","time":"2020-04-15T10:44:50.879Z"},"basePath":"..","book":{"language":""}});
        });
    </script>
</div>

        
    <script src="../gitbook/gitbook.js"></script>
    <script src="../gitbook/theme.js"></script>
    
        
        <script src="../gitbook/gitbook-plugin-livereload/plugin.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search-engine.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-search/search.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/lunr.min.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-lunr/search-lunr.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-sharing/buttons.js"></script>
        
    
        
        <script src="../gitbook/gitbook-plugin-fontsettings/fontsettings.js"></script>
        
    

    </body>
</html>

